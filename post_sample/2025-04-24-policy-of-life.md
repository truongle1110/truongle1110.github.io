---
title: 'Policy of life'
date: 2025-04-24
permalink: /posts/2025/04/policy-of-life/
author_profile: false
related: false
tags:
  - nonsense
---
Cuộc đời của mỗi con người, nếu nhìn qua lăng kính của AI, đặc biệt là Reinforcement Learning, chính là một hành trình học hỏi không ngừng, nơi ta đóng vai **agent** trong một môi trường rộng lớn, phức tạp và đầy bất định.

Khi chúng ta chào đời, ta giống như một agent mới tinh, không có nhiều kiến thức về thế giới xung quanh. Môi trường (**environment**) mà ta đối mặt là cuộc sống, nơi mọi thứ diễn ra không theo một kịch bản cố định. Không ai hướng dẫn chi tiết cho ta rằng nên sống thế nào để đạt được hạnh phúc hay thành công. Giống như RL, ta phải tự mình tương tác với môi trường, thử nghiệm các hành động (**actions**), và dần dần khám phá ra quy luật vận hành của thế giới này. 

Mỗi ngày trôi qua, ta đưa ra vô số quyết định – từ những lựa chọn nhỏ bé như ăn gì sáng nay, đến những quyết định lớn lao như chọn ngành nghề, bạn đời hay lối sống. Mỗi hành động đó đều dẫn đến một trạng thái mới (**new state**) và nhận về một phần thưởng (**reward**) – có thể là tích cực (reward > 0), hoặc tiêu cực (reward < 0). Chính những phần thưởng này giúp ta update **policy** (chuỗi các hành động) để dần dần học cách hành động tốt hơn trong tương lai.

Nhưng giống như trong RL, không phải lúc nào phần thưởng cũng đến ngay sau hành động. Nhiều khi, ta phải chấp nhận những khó khăn trước mắt để nhận được giá trị lâu dài hơn, giống như **Delayed Reward**, vốn là thử thách lớn nhất không chỉ trong thuật toán mà cả trong cuộc sống con người.

Ví dụ, khi ta quyết định học hành chăm chỉ trong nhiều năm, đó là một chuỗi hành động mà không có phần thưởng ngay lập tức. Nhưng về lâu dài, nó có thể mang lại cơ hội nghề nghiệp tốt, thu nhập cao và sự ổn định, một **cumulative reward** đáng giá.

## Đánh đổi - expoitation and exploration
Một trong những vấn đề trong RL là sự cân bằng giữa Exploration (Khám phá) và Exploitation (Khai thác). Và đây cũng chính là điều mà con người phải đối mặt mỗi ngày.